{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a86919-6118-4d6c-99ab-561b469d2564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import math\n",
    "import statistics as st\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eec47a1-ce0b-4c74-a406-6edf52cd268c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse(labels, predictions):\n",
    "    return np.mean((labels - predictions) ** 2)\n",
    "\n",
    "def prediction_scores(df, step, cfg, return_predictions=False, return_labels=False):\n",
    "    timesteps, horizon = step\n",
    "    predictions_all = []\n",
    "    labels_all = []\n",
    "    \n",
    "    def _get_score(x, timesteps, horizon, cfg, metric):\n",
    "        if sum(x != np.nan) < timesteps + horizon:\n",
    "            return np.nan\n",
    "        \n",
    "        # order, trend = cfg\n",
    "        order, seasonal_order, trend = cfg\n",
    "        inputs = x[:timesteps]\n",
    "        inputs.index.freq = 'MS'\n",
    "        \n",
    "        labels = x[timesteps:]\n",
    "        labels_all.append(labels)\n",
    "        \n",
    "        m = SARIMAX(inputs, order=order, seasonal_order=seasonal_order, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        # m = ARIMA(inputs, order=order, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        predictions = m.fit(disp=False).predict(timesteps, timesteps+horizon-1)\n",
    "        # print(predictions)\n",
    "        predictions_all.append(predictions)\n",
    "        score = metric(labels, predictions)\n",
    "        # print(score)\n",
    "        return score\n",
    "    \n",
    "    result = [df.rolling(timesteps+horizon).apply(lambda x: _get_score(x, timesteps, horizon, cfg, mse)).mean(axis=0)]\n",
    "    if return_predictions:\n",
    "        result.append(predictions_all)\n",
    "    if return_labels:\n",
    "        result.append(labels_all)\n",
    "    if len(result) == 1:\n",
    "        return result[0]\n",
    "    return tuple(result)\n",
    "\n",
    "# cfg = [(1,0,1), 'n']\n",
    "# step = [24, 6]\n",
    "# scores, pred, lab = prediction_scores(df_test['price'], step, cfg, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fca4245-2440-43dd-bc46-094da5640feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grid_search(df, cfg_list, step):\n",
    "    scores = list()\n",
    "    filterwarnings(\"ignore\")\n",
    "    best_score = np.inf\n",
    "\n",
    "    for cfg in cfg_list:\n",
    "        \n",
    "        score = prediction_scores(df, step, cfg)\n",
    "        print(f'{cfg=}, {score=}')\n",
    "\n",
    "        if score < best_score:\n",
    "            print(\"Found an improved score\", score,\"is better than\", best_score )\n",
    "            best_score = score\n",
    "            best_cfg = cfg\n",
    "\n",
    "    return best_cfg, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14f389a-b94f-4e5e-af9a-2ae6087961b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to  create a set of arimax configs to try\n",
    "def arima_config(p,d,q):\n",
    "    models = list()\n",
    "    # define config lists\n",
    "    p_params = list(range(0,p))\n",
    "    d_params = list(range(0,d))\n",
    "    q_params = list(range(0,q))\n",
    "    t_params = ['n']\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                    cfg = [(p,d,q), t]\n",
    "                    models.append(cfg)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e49f01-fa75-48b7-a5a4-be9195f168d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to  create a set of sarima configs to try\n",
    "def sarima_configs(p,d,q,P,D,Q):\n",
    "    models = list()\n",
    "    # define config lists\n",
    "    p_params = list(range(0,p))\n",
    "    d_params = list(range(0,d))\n",
    "    q_params = list(range(0,q))\n",
    "    t_params = ['n']\n",
    "    P_params = list(range(0,P))\n",
    "    D_params = list(range(0,D))\n",
    "    Q_params = list(range(0,Q))\n",
    "    m_params = [12]\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                     for P in P_params:\n",
    "                        for D in D_params:\n",
    "                            for Q in Q_params:\n",
    "                                for m in m_params:\n",
    "                                    cfg = [(p,d,q), (P,D,Q,m), t]\n",
    "                                    models.append(cfg)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60033be0-687a-45e5-b0ba-573e932ab5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function take log of price and standardize train set\n",
    "def transform_data_train(df):\n",
    "    df.price = np.log(df.price)\n",
    "    col_list = df.columns\n",
    "    mean_list = []\n",
    "    sd_list = []\n",
    "    mean = 0\n",
    "    sd = 0\n",
    "\n",
    "    for col in col_list:\n",
    "        mean = st.mean(df[col])\n",
    "        sd = st.pstdev(df[col])\n",
    "        df[col] = (df[col]-mean)/sd\n",
    "        mean_list.append(mean)\n",
    "        sd_list.append(sd)\n",
    "\n",
    "    #print(df.price)\n",
    "    #print(mean_list)\n",
    "    #print(sd_list)\n",
    "    return df, mean_list, sd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a23740-af47-435e-a290-3aab878f6998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function take log of price and standardize test set\n",
    "def transform_data_test(df,mean_list, sd_list):\n",
    "    df.price = np.log(df.price)\n",
    "    col_list = df.columns\n",
    "\n",
    "    for i in range(len(col_list)):\n",
    "        col = col_list[i]\n",
    "        df[col] = (df[col]-mean_list[i])/sd_list[i]\n",
    "\n",
    "    #print(df.head(5))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22977961-6ad7-41f3-984c-baa9086ba4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to split dataset based on date selected\n",
    "def train_test_split(df, enddate_train,startdate_test):\n",
    "    df_train = df[:enddate_train]\n",
    "    df_test = df[startdate_test:]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47b5e726-8fc4-45cc-aae5-64c96113d3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ith_step_prediction_label(predictions, labels=None, ith_step=6, horizon=6):\n",
    "    predictions = pd.concat(predictions, axis=1)\n",
    "    predictions = pd.Series([predictions.iat[i+ith_step-1, i] for i in range(len(predictions)-horizon+1)], index=predictions.index[ith_step-1:ith_step + horizon]) \n",
    "    predictions.name = 'pred'\n",
    "    if labels is None:\n",
    "        return predictions\n",
    "    \n",
    "    labels = pd.concat(labels, axis=1)\n",
    "    labels = pd.Series([labels.iat[i+ith_step-1, i] for i in range(len(labels)-horizon+1)], index=labels.index[ith_step-1:ith_step + horizon]) \n",
    "    labels.name = 'label'\n",
    "    \n",
    "    df = pd.concat([predictions, labels], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137837ad-1924-4893-a80f-0bb9f43e16a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "code_directory = cwd.parents[1]\n",
    "\n",
    "bas_directory = code_directory / \"notebooks\" / \"Bas\"\n",
    "gonem_directory = code_directory / \"notebooks\" / \"Gonem\"\n",
    "# data_file = bas_directory / \"cadeautjevoorGonemenLiza.xlsx\"\n",
    "results_directory = gonem_directory / 'arima_results'\n",
    "\n",
    "df_files = ['MAIZE_FILTERED_2023-03-03_02-09-43.xlsx', 'SUNFLOWER_FILTERED_2023-03-03_02-19-29.xlsx', 'WHEAT_FILTERED_2023-03-03_02-44-24.xlsx']\n",
    "products = ['Maize', 'Sunflower', 'Wheat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b842964d-7aa3-43fd-9726-f0509294f45b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Brazil', 'France', 'Germany', 'Hungary', 'Ukraine', 'Global'], dtype='object', name='PARTNER_Labels')\n",
      "Brazil\n",
      "France\n",
      "Germany\n",
      "Hungary\n",
      "Ukraine\n",
      "Global\n",
      "Index(['Belgium', 'Germany', 'Hungary', 'Ukraine', 'Argentina', 'Global'], dtype='object', name='PARTNER_Labels')\n",
      "Belgium\n",
      "Germany\n",
      "Hungary\n",
      "Ukraine\n",
      "Argentina\n",
      "Global\n",
      "Index(['Belgium', 'France', 'Germany', 'Romania', 'United Kingdom', 'Global'], dtype='object', name='PARTNER_Labels')\n",
      "Belgium\n",
      "France\n",
      "Germany\n",
      "Romania\n",
      "United Kingdom\n",
      "Global\n"
     ]
    }
   ],
   "source": [
    "#Import data of the required product\n",
    "#Select which country dataset you want to forcast\n",
    "\n",
    "#split the data in test and train\n",
    "enddate_train = \"2022-04-01\"\n",
    "startdate_test = \"2019-11-01\"\n",
    "\n",
    "for product, path_file in zip(products, df_files):\n",
    "    df_all = pd.read_excel(gonem_directory / path_file, header=[0, 1], index_col=0)\n",
    "    countries = df_all.columns.get_level_values(1).unique()\n",
    "    \n",
    "    for country in countries:\n",
    "        df = df_all.xs(country, axis=1, level=1, drop_level=True) #ADJUST to country\n",
    "\n",
    "        df_train_unedited, df_test_unedited = train_test_split(df, enddate_train,startdate_test )\n",
    "\n",
    "        #take log price and standardize the data\n",
    "        df_train = df_train_unedited.copy()\n",
    "        df_train, mean_list, sd_list = transform_data_train(df_train)\n",
    "\n",
    "        #Run test set\n",
    "        df_test = df_test_unedited.copy()\n",
    "        df_test = transform_data_test(df_test, mean_list,sd_list)\n",
    "        # model configs\n",
    "        p = 8\n",
    "        d = 2\n",
    "        q = 8\n",
    "        # cfg_list = arima_config(p,d, q)\n",
    "        cfg_list = sarima_configs(3,2,3,2,2,2)\n",
    "\n",
    "        step = [24,6] #history horizon and multistepforecast\n",
    "\n",
    "        # grid search on train dataset with minimum MSE\n",
    "\n",
    "        best_cfg, lowest_score = grid_search(df_train['price'], cfg_list,step)\n",
    "        # best_cfg, lowest_score, predictions_train = grid_search(df_train, cfg_list,step)\n",
    "        # best_cfg, lowest_score= [(0, 0, 1), 'n'], 1.0504044808697957\n",
    "        print('Gridsearch found with best parameters', best_cfg, \"with MSE equal to\", lowest_score)\n",
    "\n",
    "        score_train, predictions_train, labels_train = prediction_scores(df_train['price'], step, best_cfg, return_predictions=True, return_labels=True)\n",
    "        score_test, predictions_test, labels_test = prediction_scores(df_test['price'], step, best_cfg, return_predictions=True, return_labels=True)\n",
    "\n",
    "        df_out = ith_step_prediction_label(predictions_test, labels_test, ith_step=6)\n",
    "        df_out = np.exp(df_out*sd_list[df.columns.get_loc(\"price\")]+mean_list[df.columns.get_loc(\"price\")])\n",
    "\n",
    "        data_file = results_directory / f'{product}_{country}_{best_cfg=}_{lowest_score=}.csv'\n",
    "        df_out.to_csv(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1e251-6328-4313-be29-f5dbbc085e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
