{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import openpyxl # Needed for reading excel\n",
    "import pathlib\n",
    "\n",
    "import decomposition\n",
    "import models\n",
    "import data\n",
    "from metrics import smape\n",
    "from windower import WindowGenerator\n",
    "import hp_training\n",
    "import results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "code_directory = cwd.parents[1]\n",
    "gonem_directory = code_directory / \"notebooks\" / \"Gonem\"\n",
    "data_directory = code_directory / \"data\"\n",
    "hp_directory = code_directory / \"hp\"\n",
    "scenario_directory = code_directory / \"scenarios\"\n",
    "model_directory = code_directory / 'models'\n",
    "\n",
    "model = 'ARF' # SS, ARF or ED\n",
    "product = 'maize' # maize, sunflower or wheat \n",
    "\n",
    "data_type = 'in_sample' # in_sample or out_sample\n",
    "scenario = 2\n",
    "\n",
    "model_path =  model_directory / f\"{model}_{product}\"\n",
    "checkpoint_path = model_path / f\"{model}_{product}\"\n",
    "\n",
    "results_path = model_directory / f\"{model}_{product}\"\n",
    "\n",
    "results_path\n",
    "\n",
    "scenario_files = []\n",
    "for path in pathlib.Path(scenario_directory).iterdir():\n",
    "    if path.is_file():\n",
    "        scenario_files.append(path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCENARIO_OILPRICESHOCK_[183, 48, 26, 90, 82]_2023-03-10_02-56-23.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">AVG_TAVG</th>\n",
       "      <th>Corn Price Futures</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MAX_TMAX</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">renewable_energy_consumption_perc_of_total</th>\n",
       "      <th colspan=\"5\" halign=\"left\">unemployment_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARTNER_Labels</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Hungary</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>Global</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Hungary</th>\n",
       "      <th>...</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Hungary</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Hungary</th>\n",
       "      <th>Ukraine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>238.213467</td>\n",
       "      <td>125.120399</td>\n",
       "      <td>103.852255</td>\n",
       "      <td>116.129388</td>\n",
       "      <td>96.215727</td>\n",
       "      <td>447.205189</td>\n",
       "      <td>345.878032</td>\n",
       "      <td>225.155034</td>\n",
       "      <td>218.462006</td>\n",
       "      <td>238.409827</td>\n",
       "      <td>...</td>\n",
       "      <td>45.961321</td>\n",
       "      <td>12.858797</td>\n",
       "      <td>13.605825</td>\n",
       "      <td>13.299269</td>\n",
       "      <td>4.511203</td>\n",
       "      <td>10.096958</td>\n",
       "      <td>8.980330</td>\n",
       "      <td>5.606981</td>\n",
       "      <td>7.008726</td>\n",
       "      <td>8.350071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.185228</td>\n",
       "      <td>55.581487</td>\n",
       "      <td>65.415460</td>\n",
       "      <td>79.506412</td>\n",
       "      <td>90.577074</td>\n",
       "      <td>150.596080</td>\n",
       "      <td>24.373066</td>\n",
       "      <td>67.282110</td>\n",
       "      <td>81.540537</td>\n",
       "      <td>86.291146</td>\n",
       "      <td>...</td>\n",
       "      <td>1.909219</td>\n",
       "      <td>2.269171</td>\n",
       "      <td>2.843999</td>\n",
       "      <td>2.701251</td>\n",
       "      <td>2.124186</td>\n",
       "      <td>2.280336</td>\n",
       "      <td>0.864391</td>\n",
       "      <td>2.218326</td>\n",
       "      <td>2.706634</td>\n",
       "      <td>1.099230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>146.692308</td>\n",
       "      <td>20.168095</td>\n",
       "      <td>-29.860742</td>\n",
       "      <td>-50.419892</td>\n",
       "      <td>-98.247057</td>\n",
       "      <td>201.750000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>107.622222</td>\n",
       "      <td>36.388889</td>\n",
       "      <td>43.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>41.710000</td>\n",
       "      <td>8.520000</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>6.760000</td>\n",
       "      <td>7.390000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>6.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>228.163849</td>\n",
       "      <td>76.846499</td>\n",
       "      <td>47.985468</td>\n",
       "      <td>42.248987</td>\n",
       "      <td>16.463480</td>\n",
       "      <td>356.437500</td>\n",
       "      <td>330.875000</td>\n",
       "      <td>163.036330</td>\n",
       "      <td>140.056561</td>\n",
       "      <td>162.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.839375</td>\n",
       "      <td>11.130833</td>\n",
       "      <td>11.072292</td>\n",
       "      <td>12.753125</td>\n",
       "      <td>2.807500</td>\n",
       "      <td>8.174167</td>\n",
       "      <td>8.110625</td>\n",
       "      <td>3.664375</td>\n",
       "      <td>4.084583</td>\n",
       "      <td>7.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>246.068678</td>\n",
       "      <td>121.139616</td>\n",
       "      <td>101.023015</td>\n",
       "      <td>120.209032</td>\n",
       "      <td>91.978710</td>\n",
       "      <td>389.625000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>227.637049</td>\n",
       "      <td>225.650735</td>\n",
       "      <td>243.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.680417</td>\n",
       "      <td>13.277500</td>\n",
       "      <td>13.938750</td>\n",
       "      <td>13.640000</td>\n",
       "      <td>3.497917</td>\n",
       "      <td>9.502083</td>\n",
       "      <td>9.101250</td>\n",
       "      <td>5.032083</td>\n",
       "      <td>7.355833</td>\n",
       "      <td>8.503750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>254.833821</td>\n",
       "      <td>177.800263</td>\n",
       "      <td>164.291849</td>\n",
       "      <td>191.053584</td>\n",
       "      <td>183.358356</td>\n",
       "      <td>555.750000</td>\n",
       "      <td>360.625000</td>\n",
       "      <td>284.274194</td>\n",
       "      <td>287.716912</td>\n",
       "      <td>317.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>47.570000</td>\n",
       "      <td>15.270000</td>\n",
       "      <td>16.316875</td>\n",
       "      <td>15.388750</td>\n",
       "      <td>7.017500</td>\n",
       "      <td>12.416250</td>\n",
       "      <td>9.801875</td>\n",
       "      <td>7.435208</td>\n",
       "      <td>9.591042</td>\n",
       "      <td>9.272500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>276.134483</td>\n",
       "      <td>231.747995</td>\n",
       "      <td>229.864177</td>\n",
       "      <td>242.571429</td>\n",
       "      <td>239.800437</td>\n",
       "      <td>818.250000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>362.382979</td>\n",
       "      <td>371.823529</td>\n",
       "      <td>392.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>48.920000</td>\n",
       "      <td>15.530000</td>\n",
       "      <td>17.170000</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>7.440000</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>9.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AVG_TAVG                                                  \\\n",
       "PARTNER_Labels      Brazil      France     Germany     Hungary     Ukraine   \n",
       "count           212.000000  212.000000  212.000000  212.000000  212.000000   \n",
       "mean            238.213467  125.120399  103.852255  116.129388   96.215727   \n",
       "std              24.185228   55.581487   65.415460   79.506412   90.577074   \n",
       "min             146.692308   20.168095  -29.860742  -50.419892  -98.247057   \n",
       "25%             228.163849   76.846499   47.985468   42.248987   16.463480   \n",
       "50%             246.068678  121.139616  101.023015  120.209032   91.978710   \n",
       "75%             254.833821  177.800263  164.291849  191.053584  183.358356   \n",
       "max             276.134483  231.747995  229.864177  242.571429  239.800437   \n",
       "\n",
       "               Corn Price Futures    MAX_TMAX                          \\\n",
       "PARTNER_Labels             Global      Brazil      France     Germany   \n",
       "count                  212.000000  212.000000  212.000000  212.000000   \n",
       "mean                   447.205189  345.878032  225.155034  218.462006   \n",
       "std                    150.596080   24.373066   67.282110   81.540537   \n",
       "min                    201.750000  282.000000  107.622222   36.388889   \n",
       "25%                    356.437500  330.875000  163.036330  140.056561   \n",
       "50%                    389.625000  345.000000  227.637049  225.650735   \n",
       "75%                    555.750000  360.625000  284.274194  287.716912   \n",
       "max                    818.250000  401.000000  362.382979  371.823529   \n",
       "\n",
       "                            ... renewable_energy_consumption_perc_of_total  \\\n",
       "PARTNER_Labels     Hungary  ...                                     Brazil   \n",
       "count           212.000000  ...                                 212.000000   \n",
       "mean            238.409827  ...                                  45.961321   \n",
       "std              86.291146  ...                                   1.909219   \n",
       "min              43.666667  ...                                  41.710000   \n",
       "25%             162.625000  ...                                  44.839375   \n",
       "50%             243.400000  ...                                  46.680417   \n",
       "75%             317.125000  ...                                  47.570000   \n",
       "max             392.500000  ...                                  48.920000   \n",
       "\n",
       "                                                                \\\n",
       "PARTNER_Labels      France     Germany     Hungary     Ukraine   \n",
       "count           212.000000  212.000000  212.000000  212.000000   \n",
       "mean             12.858797   13.605825   13.299269    4.511203   \n",
       "std               2.269171    2.843999    2.701251    2.124186   \n",
       "min               8.520000    7.280000    7.290000    1.270000   \n",
       "25%              11.130833   11.072292   12.753125    2.807500   \n",
       "50%              13.277500   13.938750   13.640000    3.497917   \n",
       "75%              15.270000   16.316875   15.388750    7.017500   \n",
       "max              15.530000   17.170000   17.180000    7.440000   \n",
       "\n",
       "               unemployment_total                                      \\\n",
       "PARTNER_Labels             Brazil      France     Germany     Hungary   \n",
       "count                  212.000000  212.000000  212.000000  212.000000   \n",
       "mean                    10.096958    8.980330    5.606981    7.008726   \n",
       "std                      2.280336    0.864391    2.218326    2.706634   \n",
       "min                      6.760000    7.390000    3.140000    3.420000   \n",
       "25%                      8.174167    8.110625    3.664375    4.084583   \n",
       "50%                      9.502083    9.101250    5.032083    7.355833   \n",
       "75%                     12.416250    9.801875    7.435208    9.591042   \n",
       "max                     13.700000   10.350000   11.170000   11.170000   \n",
       "\n",
       "                            \n",
       "PARTNER_Labels     Ukraine  \n",
       "count           212.000000  \n",
       "mean              8.350071  \n",
       "std               1.099230  \n",
       "min               6.350000  \n",
       "25%               7.462500  \n",
       "50%               8.503750  \n",
       "75%               9.272500  \n",
       "max               9.830000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if scenario:\n",
    "    data_type = f\"{scenario_files[scenario-1]}\"\n",
    "    print(data_type)\n",
    "    df = data.get_data(scenario_directory / scenario_files[scenario-1])\n",
    "else:\n",
    "    df = data.get_data(directory_path=data_directory, product=product)\n",
    "\n",
    "\n",
    "df = df.iloc[:-2]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('price', 'Brazil'),\n",
       " ('price', 'France'),\n",
       " ('price', 'Germany'),\n",
       " ('price', 'Global'),\n",
       " ('price', 'Hungary'),\n",
       " ('price', 'Ukraine')]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_columns = ['price']\n",
    "label_columns = df.columns[df.columns.get_level_values(0).isin(label_columns)].tolist()\n",
    "label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stl = decomposition.STLDecomposer(labels=label_columns, period=12)\n",
    "log = decomposition.Logger(labels=label_columns)\n",
    "std = decomposition.Standardizer()\n",
    "\n",
    "preproc = decomposition.Processor().add(stl).add(log).add(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 30\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
       "Label indices: [24 25 26 27 28 29]\n",
       "Label column name(s): [('price', 'Brazil'), ('price', 'France'), ('price', 'Germany'), ('price', 'Global'), ('price', 'Hungary'), ('price', 'Ukraine')]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 24\n",
    "label_width = 6\n",
    "shift = 6\n",
    "\n",
    "if data_type == 'in_sample':\n",
    "    test_begin = None\n",
    "else:\n",
    "    test_begin = 0.\n",
    "    \n",
    "window = WindowGenerator(input_width=width, label_width=label_width, shift=shift, data=df, \n",
    "                    # train_begin=0, train_end=.9, val_begin=None, val_end=.96,\n",
    "                    train_begin=0., train_end=.97, val_begin=None, val_end=None,\n",
    "                    # train_begin=0, train_end=.5, val_begin=None, val_end=.8,\n",
    "                    test_begin=test_begin, test_end=1., connect=True, remove_labels=True, label_columns=label_columns)\n",
    "window.preprocess(preproc)\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_std = decomposition.Standardizer(mean=std.mean[window.label_columns], std=std.std[window.label_columns])\n",
    "label_log = decomposition.Logger(label_indices=range(len(window.label_columns)))\n",
    "postproc = decomposition.Processor().add(label_std).add(label_log)\n",
    "window.add_label_postprocess(postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from /code/hp/ARF/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = hp_training.get_tuner(model, hp_directory, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 24, 75)\n",
      "Labels shape (batch, time, features): (32, 6, 6)\n"
     ]
    }
   ],
   "source": [
    "for example_inputs, example_labels in window.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "    output_features = example_labels.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Here we train the best hp model and give it a final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "hp_training.run(tuner, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm_units': 224,\n",
       " 'lstm_layers': 1,\n",
       " 'prediction_units': 64,\n",
       " 'prediction_layers': 6,\n",
       " 'feature_units': 416,\n",
       " 'feature_layers': 8,\n",
       " 'heads': 5,\n",
       " 'dropout': 0.18732635985077017,\n",
       " 'key_dim': 112,\n",
       " 'l1': 0.0009003172160791668,\n",
       " 'l2': 0.00010979313621486196,\n",
       " 'learning_rate': 0.000291383964865669,\n",
       " 'tuner/epochs': 200,\n",
       " 'tuner/initial_epoch': 67,\n",
       " 'tuner/bracket': 2,\n",
       " 'tuner/round': 2,\n",
       " 'tuner/trial_id': '0200'}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 - 9s - loss: 214.3212 - mae: 0.7460 - mse: 0.9456 - mape: 281.0833 - smape: 159.8766 - val_loss: 186.8838 - val_mae: 0.9816 - val_mse: 1.4664 - val_mape: 689.4041 - val_smape: 132.3815 - 9s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "6/6 - 2s - loss: 201.3597 - mae: 1.0360 - mse: 1.6600 - mape: 893.3696 - smape: 146.9449 - val_loss: 185.9092 - val_mae: 1.0653 - val_mse: 1.7767 - val_mape: 1030.6014 - val_smape: 131.4389 - 2s/epoch - 259ms/step\n",
      "Epoch 3/200\n",
      "6/6 - 2s - loss: 199.9960 - mae: 1.0275 - mse: 1.7769 - mape: 840.8468 - smape: 145.8791 - val_loss: 181.2084 - val_mae: 0.8340 - val_mse: 1.1795 - val_mape: 712.1660 - val_smape: 126.2289 - 2s/epoch - 259ms/step\n",
      "Epoch 4/200\n",
      "6/6 - 2s - loss: 197.3597 - mae: 0.7738 - mse: 1.0765 - mape: 363.5034 - smape: 143.6318 - val_loss: 173.3139 - val_mae: 0.6255 - val_mse: 0.8091 - val_mape: 280.6886 - val_smape: 120.1421 - 2s/epoch - 260ms/step\n",
      "Epoch 5/200\n",
      "6/6 - 2s - loss: 191.0834 - mae: 0.7234 - mse: 0.9770 - mape: 341.5749 - smape: 137.4329 - val_loss: 164.2502 - val_mae: 0.7002 - val_mse: 0.9574 - val_mape: 601.1080 - val_smape: 109.6934 - 2s/epoch - 252ms/step\n",
      "Epoch 6/200\n",
      "6/6 - 1s - loss: 183.0341 - mae: 0.7571 - mse: 1.0403 - mape: 628.2217 - smape: 128.3738 - val_loss: 174.4820 - val_mae: 0.8096 - val_mse: 1.1117 - val_mape: 892.3261 - val_smape: 118.9229 - 1s/epoch - 231ms/step\n",
      "Epoch 7/200\n",
      "6/6 - 2s - loss: 187.4499 - mae: 0.7963 - mse: 1.1094 - mape: 794.7153 - smape: 132.7660 - val_loss: 161.4622 - val_mae: 0.6459 - val_mse: 0.8341 - val_mape: 698.0834 - val_smape: 107.0336 - 2s/epoch - 295ms/step\n",
      "Epoch 8/200\n",
      "6/6 - 1s - loss: 181.4360 - mae: 0.7154 - mse: 0.9827 - mape: 770.5117 - smape: 127.4566 - val_loss: 151.2619 - val_mae: 0.6255 - val_mse: 0.8422 - val_mape: 887.1851 - val_smape: 97.8363 - 1s/epoch - 215ms/step\n",
      "Epoch 9/200\n",
      "6/6 - 1s - loss: 172.9622 - mae: 0.6709 - mse: 0.9021 - mape: 781.7621 - smape: 119.3951 - val_loss: 146.0415 - val_mae: 0.5542 - val_mse: 0.7156 - val_mape: 671.3817 - val_smape: 92.4061 - 1s/epoch - 233ms/step\n",
      "Epoch 10/200\n",
      "6/6 - 1s - loss: 170.2457 - mae: 0.6176 - mse: 0.8199 - mape: 545.2623 - smape: 116.9301 - val_loss: 146.2974 - val_mae: 0.5177 - val_mse: 0.6659 - val_mape: 468.2289 - val_smape: 92.7070 - 1s/epoch - 237ms/step\n",
      "Epoch 11/200\n",
      "6/6 - 2s - loss: 169.8601 - mae: 0.6102 - mse: 0.7992 - mape: 489.0927 - smape: 115.8502 - val_loss: 144.3723 - val_mae: 0.5396 - val_mse: 0.7015 - val_mape: 529.4890 - val_smape: 90.4652 - 2s/epoch - 256ms/step\n",
      "Epoch 12/200\n",
      "6/6 - 1s - loss: 169.9306 - mae: 0.6126 - mse: 0.8277 - mape: 324.0166 - smape: 117.8872 - val_loss: 147.0269 - val_mae: 0.5334 - val_mse: 0.7140 - val_mape: 294.5906 - val_smape: 94.9393 - 1s/epoch - 246ms/step\n",
      "Epoch 13/200\n",
      "6/6 - 2s - loss: 166.6729 - mae: 0.5667 - mse: 0.7158 - mape: 444.8701 - smape: 113.6356 - val_loss: 139.2879 - val_mae: 0.4755 - val_mse: 0.5866 - val_mape: 454.7223 - val_smape: 86.3969 - 2s/epoch - 268ms/step\n",
      "Epoch 14/200\n",
      "6/6 - 1s - loss: 162.8667 - mae: 0.5580 - mse: 0.7242 - mape: 579.8343 - smape: 109.6856 - val_loss: 146.4969 - val_mae: 0.6547 - val_mse: 0.8979 - val_mape: 746.5765 - val_smape: 92.5992 - 1s/epoch - 244ms/step\n",
      "Epoch 15/200\n",
      "6/6 - 1s - loss: 165.8907 - mae: 0.6553 - mse: 0.8884 - mape: 567.8957 - smape: 112.0950 - val_loss: 141.4793 - val_mae: 0.4773 - val_mse: 0.5785 - val_mape: 448.1964 - val_smape: 88.0746 - 1s/epoch - 247ms/step\n",
      "Epoch 16/200\n",
      "6/6 - 2s - loss: 164.9223 - mae: 0.5392 - mse: 0.6630 - mape: 436.5283 - smape: 111.5748 - val_loss: 138.3929 - val_mae: 0.4667 - val_mse: 0.5803 - val_mape: 426.1594 - val_smape: 85.1655 - 2s/epoch - 255ms/step\n",
      "Epoch 17/200\n",
      "6/6 - 1s - loss: 159.7755 - mae: 0.5278 - mse: 0.6667 - mape: 368.8350 - smape: 106.3322 - val_loss: 133.8427 - val_mae: 0.4532 - val_mse: 0.5798 - val_mape: 371.4676 - val_smape: 80.6055 - 1s/epoch - 248ms/step\n",
      "Epoch 18/200\n",
      "6/6 - 1s - loss: 158.8846 - mae: 0.5239 - mse: 0.6749 - mape: 338.4534 - smape: 105.5295 - val_loss: 131.1185 - val_mae: 0.4301 - val_mse: 0.5621 - val_mape: 276.4934 - val_smape: 78.2473 - 1s/epoch - 229ms/step\n",
      "Epoch 19/200\n",
      "6/6 - 2s - loss: 156.2909 - mae: 0.5051 - mse: 0.6471 - mape: 355.8745 - smape: 103.1306 - val_loss: 128.7769 - val_mae: 0.4160 - val_mse: 0.5317 - val_mape: 347.9428 - val_smape: 75.8108 - 2s/epoch - 255ms/step\n",
      "Epoch 20/200\n",
      "6/6 - 2s - loss: 153.5075 - mae: 0.4950 - mse: 0.6305 - mape: 357.4648 - smape: 100.6442 - val_loss: 129.4201 - val_mae: 0.4157 - val_mse: 0.5260 - val_mape: 299.4445 - val_smape: 76.5566 - 2s/epoch - 268ms/step\n",
      "Epoch 21/200\n",
      "6/6 - 2s - loss: 154.2563 - mae: 0.4800 - mse: 0.6132 - mape: 327.3698 - smape: 100.8966 - val_loss: 128.5934 - val_mae: 0.4154 - val_mse: 0.5316 - val_mape: 294.9410 - val_smape: 75.5327 - 2s/epoch - 266ms/step\n",
      "Epoch 22/200\n",
      "6/6 - 2s - loss: 152.2615 - mae: 0.4850 - mse: 0.6148 - mape: 348.1832 - smape: 99.5353 - val_loss: 125.4941 - val_mae: 0.4009 - val_mse: 0.5172 - val_mape: 320.2570 - val_smape: 72.6531 - 2s/epoch - 262ms/step\n",
      "Epoch 23/200\n",
      "6/6 - 2s - loss: 150.8325 - mae: 0.4777 - mse: 0.6168 - mape: 253.3405 - smape: 98.1263 - val_loss: 126.2099 - val_mae: 0.4047 - val_mse: 0.5149 - val_mape: 310.0844 - val_smape: 73.5057 - 2s/epoch - 257ms/step\n",
      "Epoch 24/200\n",
      "6/6 - 2s - loss: 151.5548 - mae: 0.4666 - mse: 0.5870 - mape: 321.0421 - smape: 98.5767 - val_loss: 124.9831 - val_mae: 0.4002 - val_mse: 0.5087 - val_mape: 292.8879 - val_smape: 72.2887 - 2s/epoch - 252ms/step\n",
      "Epoch 25/200\n",
      "6/6 - 2s - loss: 150.4965 - mae: 0.4750 - mse: 0.6090 - mape: 282.8921 - smape: 97.5389 - val_loss: 124.5253 - val_mae: 0.3991 - val_mse: 0.5133 - val_mape: 277.2191 - val_smape: 71.9486 - 2s/epoch - 258ms/step\n",
      "Epoch 26/200\n",
      "6/6 - 1s - loss: 150.3319 - mae: 0.4676 - mse: 0.6030 - mape: 268.9684 - smape: 97.7336 - val_loss: 124.8956 - val_mae: 0.3996 - val_mse: 0.5111 - val_mape: 264.1917 - val_smape: 72.2650 - 1s/epoch - 231ms/step\n",
      "Epoch 27/200\n",
      "6/6 - 2s - loss: 148.8557 - mae: 0.4604 - mse: 0.5847 - mape: 236.8977 - smape: 96.0185 - val_loss: 124.4085 - val_mae: 0.3935 - val_mse: 0.5045 - val_mape: 264.2878 - val_smape: 71.7743 - 2s/epoch - 254ms/step\n",
      "Epoch 28/200\n",
      "6/6 - 1s - loss: 148.4494 - mae: 0.4615 - mse: 0.5928 - mape: 252.8283 - smape: 95.6171 - val_loss: 128.1091 - val_mae: 0.3982 - val_mse: 0.5015 - val_mape: 253.9790 - val_smape: 75.0928 - 1s/epoch - 240ms/step\n",
      "Epoch 29/200\n",
      "6/6 - 1s - loss: 151.4747 - mae: 0.4673 - mse: 0.6045 - mape: 278.6790 - smape: 98.6436 - val_loss: 124.7392 - val_mae: 0.3921 - val_mse: 0.4995 - val_mape: 257.8969 - val_smape: 72.1539 - 1s/epoch - 240ms/step\n",
      "Epoch 30/200\n",
      "6/6 - 1s - loss: 151.9165 - mae: 0.4746 - mse: 0.6086 - mape: 281.5450 - smape: 99.3690 - val_loss: 124.4643 - val_mae: 0.3912 - val_mse: 0.5012 - val_mape: 275.9026 - val_smape: 71.8532 - 1s/epoch - 244ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.AutoregressiveFeedback at 0x7fa6a024f430>"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_training.final_train(tuner, window, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here on out, it is assumed that best_model is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fa63d8c55b0>"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tuner.hypermodel.build(best_hps)\n",
    "m.load_weights(checkpoint_path)\n",
    "# m.evaluate(window.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# window.test\n",
    "\n",
    "# # val_performance['1'] = m.evaluate(w.val)\n",
    "# for i in range(6):\n",
    "\n",
    "#     label = label_columns[i]\n",
    "#     print(label)\n",
    "#     # performance['1'] = m.evaluate(w.test)\n",
    "#     window.plot(m, plot_col=label, max_subplots=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs, labels, predictions, weights, mcds = [], [], [], [], []\n",
    "for x, y in window.test.take(40):\n",
    "    inputs.append(x)\n",
    "    lab = y\n",
    "    lab = window.label_postprocessor.reverse(lab)\n",
    "    labels.append(lab)\n",
    "    \n",
    "    pred = m(x)\n",
    "    pred = window.label_postprocessor.reverse(pred)\n",
    "    predictions.append(pred)\n",
    "    \n",
    "    weight = m.attention_layer(x, return_weights=True)[1]\n",
    "    weights.append(weight)\n",
    "    \n",
    "    mcd = results.monte_carlo_dropout(x, m, 100, window.label_postprocessor.reverse, return_weight=False)\n",
    "    mcds.append(mcd)\n",
    "    weights.append(weight)\n",
    "    \n",
    "inputs = tf.concat(inputs, axis=0)\n",
    "labels = tf.concat(labels, axis=0)\n",
    "weights = tf.concat(weights, axis=0)\n",
    "weights = tf.reduce_mean(weights, axis=0)\n",
    "predictions = tf.concat(predictions, axis=0)\n",
    "mcds = tf.concat(mcds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(model_path / f\"{product}_inputs_{data_type}\", inputs.numpy())\n",
    "np.save(model_path / f\"{product}_labels_{data_type}\", labels.numpy())\n",
    "np.save(model_path / f\"{product}_weights_{data_type}\", weights.numpy())\n",
    "np.save(model_path / f\"{product}_predictions_{data_type}\", predictions.numpy())\n",
    "np.save(model_path / f\"{product}_mcd_predictions_{data_type}\", mcds.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e074677d39952796133ff6b8faa8a2f37c9c99b6d1afd7ec75658d1c00e599"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
