{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import openpyxl # Needed for reading excel\n",
    "import pathlib\n",
    "\n",
    "import decomposition\n",
    "import models\n",
    "import data\n",
    "from metrics import smape\n",
    "from windower import WindowGenerator\n",
    "import hp_training\n",
    "import results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "code_directory = cwd.parents[1]\n",
    "gonem_directory = code_directory / \"notebooks\" / \"Gonem\"\n",
    "data_directory = code_directory / \"data\"\n",
    "hp_directory = code_directory / \"hp\"\n",
    "scenario_directory = code_directory / \"scenarios\"\n",
    "model_directory = code_directory / 'models'\n",
    "\n",
    "model = 'ED' # SS, ARF or ED\n",
    "product = 'wheat' # maize, sunflower or wheat \n",
    "\n",
    "data_type = 'in_sample' # in_sample or out_sample\n",
    "scenario = 0\n",
    "\n",
    "model_path =  model_directory / f\"{model}_{product}\"\n",
    "checkpoint_path = model_path / f\"{model}_{product}\"\n",
    "\n",
    "results_path = model_directory / f\"{model}_{product}\"\n",
    "\n",
    "results_path\n",
    "\n",
    "scenario_files = []\n",
    "for path in pathlib.Path(scenario_directory).iterdir():\n",
    "    if path.is_file():\n",
    "        scenario_files.append(path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">AVG_TAVG</th>\n",
       "      <th colspan=\"5\" halign=\"left\">MAX_TMAX</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">renewable_energy_consumption_perc_of_total</th>\n",
       "      <th colspan=\"5\" halign=\"left\">unemployment_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARTNER_Labels</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Romania</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Romania</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>...</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Romania</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Romania</th>\n",
       "      <th>United Kingdom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.302520</td>\n",
       "      <td>125.494113</td>\n",
       "      <td>104.143755</td>\n",
       "      <td>105.397067</td>\n",
       "      <td>96.544608</td>\n",
       "      <td>215.733645</td>\n",
       "      <td>225.531663</td>\n",
       "      <td>218.804582</td>\n",
       "      <td>224.761987</td>\n",
       "      <td>168.507655</td>\n",
       "      <td>...</td>\n",
       "      <td>7.672173</td>\n",
       "      <td>12.883762</td>\n",
       "      <td>13.639136</td>\n",
       "      <td>22.297593</td>\n",
       "      <td>7.120444</td>\n",
       "      <td>7.272757</td>\n",
       "      <td>8.969860</td>\n",
       "      <td>5.587944</td>\n",
       "      <td>6.091075</td>\n",
       "      <td>5.505070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.100073</td>\n",
       "      <td>55.456797</td>\n",
       "      <td>65.178828</td>\n",
       "      <td>81.500731</td>\n",
       "      <td>39.315210</td>\n",
       "      <td>79.022190</td>\n",
       "      <td>67.153277</td>\n",
       "      <td>81.278888</td>\n",
       "      <td>81.711107</td>\n",
       "      <td>50.004673</td>\n",
       "      <td>...</td>\n",
       "      <td>2.698506</td>\n",
       "      <td>2.273139</td>\n",
       "      <td>2.851412</td>\n",
       "      <td>2.019432</td>\n",
       "      <td>3.915944</td>\n",
       "      <td>0.994389</td>\n",
       "      <td>0.867082</td>\n",
       "      <td>2.216610</td>\n",
       "      <td>0.996584</td>\n",
       "      <td>1.547705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.733333</td>\n",
       "      <td>20.168095</td>\n",
       "      <td>-29.860742</td>\n",
       "      <td>-65.129397</td>\n",
       "      <td>7.340256</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>107.622222</td>\n",
       "      <td>36.388889</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>8.520000</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>17.390000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>7.390000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>3.910000</td>\n",
       "      <td>3.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.525974</td>\n",
       "      <td>77.127932</td>\n",
       "      <td>48.280935</td>\n",
       "      <td>29.836943</td>\n",
       "      <td>61.896038</td>\n",
       "      <td>147.500000</td>\n",
       "      <td>163.656487</td>\n",
       "      <td>140.181174</td>\n",
       "      <td>157.733333</td>\n",
       "      <td>124.583333</td>\n",
       "      <td>...</td>\n",
       "      <td>5.438125</td>\n",
       "      <td>11.155000</td>\n",
       "      <td>11.109375</td>\n",
       "      <td>21.416250</td>\n",
       "      <td>3.506875</td>\n",
       "      <td>6.260000</td>\n",
       "      <td>8.086250</td>\n",
       "      <td>3.646250</td>\n",
       "      <td>5.508333</td>\n",
       "      <td>3.918750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>104.345960</td>\n",
       "      <td>121.548459</td>\n",
       "      <td>102.466712</td>\n",
       "      <td>104.869216</td>\n",
       "      <td>96.188597</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>228.556851</td>\n",
       "      <td>226.650735</td>\n",
       "      <td>229.750000</td>\n",
       "      <td>164.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>9.016250</td>\n",
       "      <td>13.286667</td>\n",
       "      <td>13.971250</td>\n",
       "      <td>23.290833</td>\n",
       "      <td>7.192500</td>\n",
       "      <td>7.460000</td>\n",
       "      <td>9.068750</td>\n",
       "      <td>5.011250</td>\n",
       "      <td>6.412083</td>\n",
       "      <td>5.278750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>163.724856</td>\n",
       "      <td>177.640994</td>\n",
       "      <td>163.845330</td>\n",
       "      <td>182.880379</td>\n",
       "      <td>131.974731</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>284.822581</td>\n",
       "      <td>287.334967</td>\n",
       "      <td>300.500000</td>\n",
       "      <td>208.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>16.448125</td>\n",
       "      <td>23.540000</td>\n",
       "      <td>11.380625</td>\n",
       "      <td>8.149583</td>\n",
       "      <td>9.789167</td>\n",
       "      <td>7.403125</td>\n",
       "      <td>6.926250</td>\n",
       "      <td>7.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>239.666667</td>\n",
       "      <td>231.747995</td>\n",
       "      <td>229.864177</td>\n",
       "      <td>243.079179</td>\n",
       "      <td>178.133333</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>362.382979</td>\n",
       "      <td>371.823529</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>300.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>10.660000</td>\n",
       "      <td>15.530000</td>\n",
       "      <td>17.170000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>12.240000</td>\n",
       "      <td>8.520000</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>8.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AVG_TAVG                                                     \\\n",
       "PARTNER_Labels     Belgium      France     Germany     Romania United Kingdom   \n",
       "count           214.000000  214.000000  214.000000  214.000000     214.000000   \n",
       "mean            111.302520  125.494113  104.143755  105.397067      96.544608   \n",
       "std              57.100073   55.456797   65.178828   81.500731      39.315210   \n",
       "min              -0.733333   20.168095  -29.860742  -65.129397       7.340256   \n",
       "25%              63.525974   77.127932   48.280935   29.836943      61.896038   \n",
       "50%             104.345960  121.548459  102.466712  104.869216      96.188597   \n",
       "75%             163.724856  177.640994  163.845330  182.880379     131.974731   \n",
       "max             239.666667  231.747995  229.864177  243.079179     178.133333   \n",
       "\n",
       "                  MAX_TMAX                                                     \\\n",
       "PARTNER_Labels     Belgium      France     Germany     Romania United Kingdom   \n",
       "count           214.000000  214.000000  214.000000  214.000000     214.000000   \n",
       "mean            215.733645  225.531663  218.804582  224.761987     168.507655   \n",
       "std              79.022190   67.153277   81.278888   81.711107      50.004673   \n",
       "min              59.000000  107.622222   36.388889   47.000000      74.500000   \n",
       "25%             147.500000  163.656487  140.181174  157.733333     124.583333   \n",
       "50%             223.000000  228.556851  226.650735  229.750000     164.437500   \n",
       "75%             281.000000  284.822581  287.334967  300.500000     208.409091   \n",
       "max             397.000000  362.382979  371.823529  367.750000     300.562500   \n",
       "\n",
       "                ... renewable_energy_consumption_perc_of_total              \\\n",
       "PARTNER_Labels  ...                                    Belgium      France   \n",
       "count           ...                                 214.000000  214.000000   \n",
       "mean            ...                                   7.672173   12.883762   \n",
       "std             ...                                   2.698506    2.273139   \n",
       "min             ...                                   2.460000    8.520000   \n",
       "25%             ...                                   5.438125   11.155000   \n",
       "50%             ...                                   9.016250   13.286667   \n",
       "75%             ...                                  10.210000   15.310000   \n",
       "max             ...                                  10.660000   15.530000   \n",
       "\n",
       "                                                      unemployment_total  \\\n",
       "PARTNER_Labels     Germany     Romania United Kingdom            Belgium   \n",
       "count           214.000000  214.000000     214.000000         214.000000   \n",
       "mean             13.639136   22.297593       7.120444           7.272757   \n",
       "std               2.851412    2.019432       3.915944           0.994389   \n",
       "min               7.280000   17.390000       1.350000           5.360000   \n",
       "25%              11.109375   21.416250       3.506875           6.260000   \n",
       "50%              13.971250   23.290833       7.192500           7.460000   \n",
       "75%              16.448125   23.540000      11.380625           8.149583   \n",
       "max              17.170000   24.400000      12.240000           8.520000   \n",
       "\n",
       "                                                                   \n",
       "PARTNER_Labels      France     Germany     Romania United Kingdom  \n",
       "count           214.000000  214.000000  214.000000     214.000000  \n",
       "mean              8.969860    5.587944    6.091075       5.505070  \n",
       "std               0.867082    2.216610    0.996584       1.547705  \n",
       "min               7.390000    3.140000    3.910000       3.740000  \n",
       "25%               8.086250    3.646250    5.508333       3.918750  \n",
       "50%               9.068750    5.011250    6.412083       5.278750  \n",
       "75%               9.789167    7.403125    6.926250       7.140625  \n",
       "max              10.350000   11.170000    7.270000       8.040000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if scenario:\n",
    "    data_type = f\"{scenario_files[scenario-1]}\"\n",
    "    print(data_type)\n",
    "    df = data.get_data(scenario_directory / scenario_files[scenario-1])\n",
    "else:\n",
    "    df = data.get_data(directory_path=data_directory, product=product)\n",
    "\n",
    "\n",
    "df = df.iloc[:-2]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('price', 'Belgium'),\n",
       " ('price', 'France'),\n",
       " ('price', 'Germany'),\n",
       " ('price', 'Global'),\n",
       " ('price', 'Romania'),\n",
       " ('price', 'United Kingdom')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_columns = ['price']\n",
    "label_columns = df.columns[df.columns.get_level_values(0).isin(label_columns)].tolist()\n",
    "label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stl = decomposition.STLDecomposer(labels=label_columns, period=12)\n",
    "log = decomposition.Logger(labels=label_columns)\n",
    "std = decomposition.Standardizer()\n",
    "\n",
    "preproc = decomposition.Processor().add(stl).add(log).add(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 30\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
       "Label indices: [24 25 26 27 28 29]\n",
       "Label column name(s): [('price', 'Belgium'), ('price', 'France'), ('price', 'Germany'), ('price', 'Global'), ('price', 'Romania'), ('price', 'United Kingdom')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 24\n",
    "label_width = 6\n",
    "shift = 6\n",
    "\n",
    "if data_type == 'in_sample':\n",
    "    test_begin = None\n",
    "else:\n",
    "    test_begin = 0.\n",
    "    \n",
    "window = WindowGenerator(input_width=width, label_width=label_width, shift=shift, data=df, \n",
    "                    # train_begin=0, train_end=.9, val_begin=None, val_end=.96,\n",
    "                    train_begin=0., train_end=.97, val_begin=None, val_end=None,\n",
    "                    # train_begin=0, train_end=.5, val_begin=None, val_end=.8,\n",
    "                    test_begin=test_begin, test_end=1., connect=True, remove_labels=True, label_columns=label_columns)\n",
    "window.preprocess(preproc)\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_std = decomposition.Standardizer(mean=std.mean[window.label_columns], std=std.std[window.label_columns])\n",
    "label_log = decomposition.Logger(label_indices=range(len(window.label_columns)))\n",
    "postproc = decomposition.Processor().add(label_std).add(label_log)\n",
    "window.add_label_postprocess(postproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from /code/hp/ED/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = hp_training.get_tuner(model, hp_directory, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 24, 75)\n",
      "Labels shape (batch, time, features): (32, 6, 6)\n"
     ]
    }
   ],
   "source": [
    "for example_inputs, example_labels in window.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "    output_features = example_labels.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Here we train the best hp model and give it a final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hp_training.run(tuner, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder_units': 256,\n",
       " 'encoder_layers': 2,\n",
       " 'decoder_units': 224,\n",
       " 'decoder_layers': 4,\n",
       " 'dense_units': 320,\n",
       " 'dense_layers': 5,\n",
       " 'heads': 4,\n",
       " 'dropout': 0.0656398128830259,\n",
       " 'key_dim': 32,\n",
       " 'l1': 5.169932032477925e-07,\n",
       " 'l2': 0.00010441578807915571,\n",
       " 'learning_rate': 0.00024152676688158866,\n",
       " 'tuner/epochs': 200,\n",
       " 'tuner/initial_epoch': 67,\n",
       " 'tuner/bracket': 3,\n",
       " 'tuner/round': 3,\n",
       " 'tuner/trial_id': '0203'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 - 12s - loss: 189.2620 - mae: 0.7683 - mse: 0.9404 - mape: 102.5098 - smape: 187.1148 - val_loss: 168.5220 - val_mae: 0.7652 - val_mse: 0.9552 - val_mape: 120.3482 - val_smape: 167.1693 - 12s/epoch - 2s/step\n",
      "Epoch 2/200\n",
      "6/6 - 1s - loss: 158.0757 - mae: 0.7737 - mse: 0.9940 - mape: 138.4746 - smape: 156.5593 - val_loss: 139.9650 - val_mae: 0.8332 - val_mse: 1.1891 - val_mape: 219.7452 - val_smape: 139.6573 - 795ms/epoch - 132ms/step\n",
      "Epoch 3/200\n",
      "6/6 - 1s - loss: 145.9551 - mae: 0.9981 - mse: 1.5213 - mape: 283.6198 - smape: 146.4142 - val_loss: 137.8200 - val_mae: 1.1261 - val_mse: 1.9731 - val_mape: 401.7635 - val_smape: 138.6097 - 870ms/epoch - 145ms/step\n",
      "Epoch 4/200\n",
      "6/6 - 1s - loss: 140.9851 - mae: 1.1364 - mse: 2.0299 - mape: 403.2751 - smape: 141.5529 - val_loss: 132.1713 - val_mae: 0.9902 - val_mse: 1.5936 - val_mape: 333.7762 - val_smape: 132.6933 - 775ms/epoch - 129ms/step\n",
      "Epoch 5/200\n",
      "6/6 - 1s - loss: 137.8001 - mae: 0.9737 - mse: 1.5317 - mape: 322.5908 - smape: 137.8095 - val_loss: 132.7227 - val_mae: 0.9259 - val_mse: 1.3924 - val_mape: 282.9371 - val_smape: 132.8053 - 661ms/epoch - 110ms/step\n",
      "Epoch 6/200\n",
      "6/6 - 1s - loss: 136.9347 - mae: 0.9534 - mse: 1.4722 - mape: 293.4414 - smape: 137.1868 - val_loss: 130.5869 - val_mae: 0.9728 - val_mse: 1.5527 - val_mape: 315.1424 - val_smape: 130.9454 - 779ms/epoch - 130ms/step\n",
      "Epoch 7/200\n",
      "6/6 - 1s - loss: 134.8376 - mae: 1.0124 - mse: 1.6672 - mape: 332.5820 - smape: 135.5563 - val_loss: 129.9394 - val_mae: 1.0130 - val_mse: 1.6828 - val_mape: 342.6944 - val_smape: 130.5322 - 764ms/epoch - 127ms/step\n",
      "Epoch 8/200\n",
      "6/6 - 1s - loss: 135.2623 - mae: 1.0169 - mse: 1.6810 - mape: 338.8883 - smape: 135.8298 - val_loss: 129.9831 - val_mae: 0.9830 - val_mse: 1.5934 - val_mape: 323.9574 - val_smape: 130.4576 - 761ms/epoch - 127ms/step\n",
      "Epoch 9/200\n",
      "6/6 - 1s - loss: 135.0561 - mae: 0.9864 - mse: 1.5961 - mape: 321.4275 - smape: 135.5347 - val_loss: 129.7287 - val_mae: 0.9730 - val_mse: 1.5759 - val_mape: 311.6080 - val_smape: 130.1533 - 762ms/epoch - 127ms/step\n",
      "Epoch 10/200\n",
      "6/6 - 1s - loss: 133.8335 - mae: 0.9866 - mse: 1.6245 - mape: 314.5608 - smape: 134.2641 - val_loss: 128.7794 - val_mae: 0.9891 - val_mse: 1.6524 - val_mape: 321.2202 - val_smape: 129.1650 - 782ms/epoch - 130ms/step\n",
      "Epoch 11/200\n",
      "6/6 - 1s - loss: 133.8084 - mae: 0.9962 - mse: 1.6828 - mape: 312.6248 - smape: 134.1299 - val_loss: 128.5486 - val_mae: 0.9732 - val_mse: 1.6252 - val_mape: 302.3842 - val_smape: 128.8648 - 775ms/epoch - 129ms/step\n",
      "Epoch 12/200\n",
      "6/6 - 1s - loss: 133.7772 - mae: 0.9982 - mse: 1.6881 - mape: 309.2941 - smape: 134.1277 - val_loss: 128.3288 - val_mae: 0.9799 - val_mse: 1.6441 - val_mape: 303.4254 - val_smape: 128.6798 - 766ms/epoch - 128ms/step\n",
      "Epoch 13/200\n",
      "6/6 - 1s - loss: 132.8691 - mae: 0.9828 - mse: 1.6613 - mape: 298.0838 - smape: 133.1132 - val_loss: 127.9480 - val_mae: 0.9697 - val_mse: 1.6489 - val_mape: 286.0003 - val_smape: 128.2527 - 785ms/epoch - 131ms/step\n",
      "Epoch 14/200\n",
      "6/6 - 1s - loss: 132.9394 - mae: 0.9839 - mse: 1.6927 - mape: 287.0113 - smape: 133.1701 - val_loss: 127.5961 - val_mae: 0.9731 - val_mse: 1.6664 - val_mape: 289.2739 - val_smape: 127.8687 - 778ms/epoch - 130ms/step\n",
      "Epoch 15/200\n",
      "6/6 - 1s - loss: 132.6826 - mae: 0.9788 - mse: 1.6602 - mape: 284.2504 - smape: 132.8629 - val_loss: 130.0185 - val_mae: 0.9319 - val_mse: 1.5539 - val_mape: 240.8677 - val_smape: 129.7581 - 611ms/epoch - 102ms/step\n",
      "Epoch 16/200\n",
      "6/6 - 1s - loss: 135.7438 - mae: 0.9267 - mse: 1.5175 - mape: 240.6129 - smape: 135.4231 - val_loss: 126.7177 - val_mae: 0.9409 - val_mse: 1.6175 - val_mape: 279.7246 - val_smape: 126.8675 - 771ms/epoch - 128ms/step\n",
      "Epoch 17/200\n",
      "6/6 - 1s - loss: 128.2470 - mae: 0.9697 - mse: 1.7241 - mape: 307.8777 - smape: 127.8988 - val_loss: 123.5991 - val_mae: 0.9518 - val_mse: 1.5933 - val_mape: 316.0021 - val_smape: 122.7569 - 813ms/epoch - 136ms/step\n",
      "Epoch 18/200\n",
      "6/6 - 1s - loss: 135.7267 - mae: 0.9887 - mse: 1.5785 - mape: 314.0408 - smape: 136.2743 - val_loss: 129.3201 - val_mae: 0.9429 - val_mse: 1.4867 - val_mape: 300.9504 - val_smape: 129.7494 - 722ms/epoch - 120ms/step\n",
      "Epoch 19/200\n",
      "6/6 - 1s - loss: 131.9846 - mae: 0.9274 - mse: 1.4659 - mape: 286.6789 - smape: 131.7600 - val_loss: 125.4906 - val_mae: 0.9165 - val_mse: 1.4598 - val_mape: 278.6210 - val_smape: 125.2301 - 643ms/epoch - 107ms/step\n",
      "Epoch 20/200\n",
      "6/6 - 1s - loss: 130.7477 - mae: 0.9045 - mse: 1.4232 - mape: 264.9885 - smape: 130.4413 - val_loss: 123.8594 - val_mae: 0.8566 - val_mse: 1.3285 - val_mape: 246.7031 - val_smape: 123.1827 - 614ms/epoch - 102ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.EncoderDecoder at 0x7f693e524fa0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_training.final_train(tuner, window, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here on out, it is assumed that best_model is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f693e831190>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tuner.hypermodel.build(best_hps)\n",
    "m.load_weights(checkpoint_path)\n",
    "# m.evaluate(window.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# window.test\n",
    "\n",
    "# # val_performance['1'] = m.evaluate(w.val)\n",
    "# for i in range(6):\n",
    "\n",
    "#     label = label_columns[i]\n",
    "#     print(label)\n",
    "#     # performance['1'] = m.evaluate(w.test)\n",
    "#     window.plot(m, plot_col=label, max_subplots=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs, labels, predictions, weights, mcds = [], [], [], [], []\n",
    "for x, y in window.test.take(40):\n",
    "    inputs.append(x)\n",
    "    lab = y\n",
    "    lab = window.label_postprocessor.reverse(lab)\n",
    "    labels.append(lab)\n",
    "    \n",
    "    pred = m(x)\n",
    "    pred = window.label_postprocessor.reverse(pred)\n",
    "    predictions.append(pred)\n",
    "    \n",
    "    weight = m.attention_layer(x, return_weights=True)[1]\n",
    "    weights.append(weight)\n",
    "    \n",
    "    mcd = results.monte_carlo_dropout(x, m, 100, window.label_postprocessor.reverse, return_weight=False)\n",
    "    mcds.append(mcd)\n",
    "    weights.append(weight)\n",
    "    \n",
    "inputs = tf.concat(inputs, axis=0)\n",
    "labels = tf.concat(labels, axis=0)\n",
    "weights = tf.concat(weights, axis=0)\n",
    "weights = tf.reduce_mean(weights, axis=0)\n",
    "predictions = tf.concat(predictions, axis=0)\n",
    "mcds = tf.concat(mcds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(model_path / f\"{product}_inputs_{data_type}\", inputs.numpy())\n",
    "np.save(model_path / f\"{product}_labels_{data_type}\", labels.numpy())\n",
    "np.save(model_path / f\"{product}_weights_{data_type}\", weights.numpy())\n",
    "np.save(model_path / f\"{product}_predictions_{data_type}\", predictions.numpy())\n",
    "np.save(model_path / f\"{product}_mcd_predictions_{data_type}\", mcds.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e074677d39952796133ff6b8faa8a2f37c9c99b6d1afd7ec75658d1c00e599"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
